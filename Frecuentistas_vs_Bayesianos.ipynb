{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVj3CY782kfVY4h1UQhhZL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaricelaMH/SIMULACION-II/blob/main/Frecuentistas_vs_Bayesianos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # F R E C U E N T I S T A S   _  V S  _  B A Y E S I A N O S\n",
        "\n",
        " Principalmente el desacuerdo de los frecuentistas con los bayesianos es la definición de probabilidad.\n",
        "\n",
        "1. **Definición frecuentista de la probabilidad:** Sostiene que la\n",
        "probabilidad de un evento es el límite al que tiende la frecuencia relativa de ocurrencia de dicho evento cuando el número de ensayos se incrementa indefinidamente. Es decir, según los frecuentistas, la probabilidad se basa en la observación empírica de eventos repetidos bajo condiciones similares.\n",
        "\n",
        "* Si realizamos un experimento muchas veces, la probabilidad de un evento $A$ se define como el valor al que tiende la proporción de veces que ocurre $A$ en relación al número total de ensayos.\n",
        "\n",
        "* Matemáticamente, se expresa como:\n",
        "\n",
        "\\\\\n",
        " $$ P(A) = \\lim_{n \\to ∞ } ( \\frac{\\text{Número de veces que ocurre el evento $A$}}{\\text{Número total de repeticiones del experimento}} )$$\n",
        "\n",
        "\\\\\n",
        "2. **Definición bayesiana de la probabilidad:** La probabilidad en el enfoque bayesiano se basa en el teorema de Bayes, que establece cómo actualizar las creencias o probabilidades iniciales (llamadas probabilidades a priori) cuando se adquieren nuevos datos o evidencia, resultando en una nueva probabilidad a posteriori.\n",
        "\n",
        "* El teorema de Bayes se expresa matemáticamente como:\n",
        "\n",
        "$$P(A|B)=\\frac{P(B|A)* P(A)}{P(B)}$$\n",
        "\n",
        "Donde:\n",
        "\n",
        "* $P(A∣B)$ es la probabilidad de $A$ dado que se ha observado $B$ (la probabilidad a posteriori).\n",
        "\n",
        "* $P(B∣A)$ es la probabilidad de observar $B$ si $A$ es verdadero.\n",
        "\n",
        "* $P(A)$ es la probabilidad de $A$ antes de observar $B$ (la probabilidad a priori)\n",
        "\n",
        "* $P(B)$ es la probabilidad total de observar $B$.\n",
        "\n",
        "Esta diferencia que podría decirse que es sutil, puede llevar, en la práctica, a enfoques muy diferentes para el análisis estadístico de datos. A continuación, exploraremos algunos ejemplos elegidos para ilustrar las diferencias de enfoque, junto con el código Python asociado para demostrar los aspectos prácticos de los enfoques frecuentista y bayesiano.\n",
        "\n"
      ],
      "metadata": {
        "id": "xK4-0a6b3XlD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 1: Mediciones del flujo de fotones\n",
        "Apuntamos un telescopio al cielo y observamos la luz que proviene de una sola estrella. Para simplificar, supondremos que el flujo fotónico real de la estrella es constante con el tiempo, es decir ,que tiene un valor fijo $F$, también ignoraremos efectos como los errores sistemáticos del fondo del cielo. Supondremos que se realizan una serie de $N$ mediciones, donde la i-ésima medición informa el flujo observado $F_i$ y el error $e_i$. La pregunta es dado este conjunto de mediciones $D = \\{F_i, e_i\\}$, ¿cuál es nuestra mejor estimación del flujo verdadero $F$?"
      ],
      "metadata": {
        "id": "GCJNv6cC-E0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* El articulo nos menciona primeramente que debemos de generar una muestra com media 1000 y en error definido como $e$:"
      ],
      "metadata": {
        "id": "-MpwcNpSkjNP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "R-E_BG0_3Wiz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(2) # Si ejecutamos el código con la misma semilla (en este caso, 2), obtendremos los mismos números aleatorios\n",
        "\n",
        "# Generamos muestras de números aleatorios de una distribución normal\n",
        "e = np.random.normal(30, 3, 50) # Ponemos los datos de la media, desviacion estádar y tamaño de la muestra\n",
        "F = np.random.normal(1000, e) # Generamos un array de 50 valores con media 1000 y desviación estándar e"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Ahora dadas las mediciones y errores anteriores , ¿cuál es nuestra mejor estimación puntual del flujo verdadero?, por lo que el articulo nos da dos enfoques de solución, el frecuentista y el bayesiano."
      ],
      "metadata": {
        "id": "xPzBYB6umkM7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### -> Enfoque frecuentista para la medición del flujo\n",
        "Por razones de simplicidad analítica y precisión numérica, la log-verosimilitud se utiliza para este fin, ya que maximizar la log-verosimilitud es equivalente a maximizar la verosimilitud, por lo que es más conveniente considerar la log-verosimilitud (transforma multiplicaciones de probabilidades en sumas) en lugar de la verosimilitud directa, por lo que esta biene definida como:\n",
        "\n",
        " $$ log \\mathscr{L} (D|F) = -\\frac{1}{2} \\sum_{i=1}^{N} [ log(2\\pi e_i^2)+\\frac{(F_i - F)^2}{e_i^2}]$$\n",
        "\n",
        "Nos gustaría determinar el valor de $F$ que maximiza la probabilidad. Para este problema simple, la maximización se puede calcular analíticamente, estableciendo (por ejemplo, estableciendo $\\frac{d log \\mathscr{L}}{dF}=0$), el resultado de esta maximización lleva a la siguiente estimación puntual de $F$:\n",
        "\n",
        "$$\\hat{F} = \\frac{\\sum{w_i F_i}}{\\sum{w_i}}$$\n",
        "\n",
        "Se toma cada valor en $e$ (la desviación estándar de cada elemento en $F$) y se calcula el peso correspondiente como\n",
        "\n",
        "$$w_i = \\frac{1}{e^2_i}$$\n",
        "\n",
        "el uso de $e^2_i$ indica que los valores con una mayor desviación estándar ($e$) tendrán menor peso en el promedio ponderado.\n",
        "\n",
        "De ogual manera podemos preguntarnos cuál es la incertidumbre de nuestra estimación. Una forma de lograrlo en el enfoque frecuentista es construir una aproximación gaussiana a la probabilidad máxima, por lo que se obtiene que:\n",
        "\n",
        "$$\\sigma_{\\hat{F}}=(\\sum_{i=1}^{N} w_i)^{-\\frac{1}{2}}$$\n",
        "\n",
        "lo implementamos de la siguiente manera:"
      ],
      "metadata": {
        "id": "YHvtRv-7piHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculamos los pesos inversamente proporcionales al cuadrado del error\n",
        "w = 1. / e ** 2  # 1./ es una forma de dividir 1.0 por el valor que sigue\n",
        "F_hat = np.sum(w * F) / np.sum(w)\n",
        "sigma_F = w.sum() ** -0.5\n",
        "print(\"El valor F que maximiza la probabilidad es: \",round(F_hat,2))\n",
        "print(\"La incertidumbre asociada a la estimación es: \",round(sigma_F,2))"
      ],
      "metadata": {
        "id": "u_9hB7LPpsRL",
        "outputId": "ce8d0568-18df-4ef0-b606-787e60ee91a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El valor F que maximiza la probabilidad es:  998.65\n",
            "La incertidumbre asociada a la estimación es:  4.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### -> Enfoque bayesiano para la medición del flujo\n",
        "\n",
        "Como es de esperar, el enfoque bayesiano comienza y termina con probabilidades. El resultado fundamental de interés es nuestro conocimiento de los parámetros en cuestión, para calcular este resultado, aplicamos a continuación el teorema de Bayes, una ley fundamental de la probabilidad:\n",
        "\n",
        "$$P(F|D)=\\frac{P(D|F) P(F)}{P(D)}$$\n",
        "\n",
        "donde:\n",
        "\n",
        "* $P(F|D)$: es la probabilidad de los parámetros del modelo dados los datos.\n",
        "* $P(D|F)$: que es proporcional a la $\\mathscr{L} (D|F)$ utilizada en el enfoque frecuentista.\n",
        "* $P(F)$: El modelo anterior, que codifica lo que sabíamos sobre el modelo antes de considerar los datos $D$.\n",
        "* $P(D)$: La evidencia del modelo, que en la práctica equivale simplemente a un término de normalización.\n",
        "\n",
        "su planteamiento es fundamentalmente contrario a la filosofia frecuentista, que dice que las probabilidades no tienen significado para parámetros fijos del modelo como F. Sin embargo, en la concepción bayesiana de la probabilidad esto no plantea ningún problema.\n",
        "Es decir, con una distribución previa plana en F, la distribución posterior bayesiana se maximiza exactamente en el mismo valor que el resultado frecuentista. Por lo tanto, a pesar de las diferencias filosóficas, vemos que las estimaciones puntuales bayesianas y frecuentistas son equivalentes para este problema simple."
      ],
      "metadata": {
        "id": "sJbCYELT76Gz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### -> Divergencia de resultados\n",
        "\n",
        "En el ejemplo simple anterior, los enfoques frecuentista y bayesiano arrojan básicamente el mismo resultado. Sin embargo, si bien es fácil demostrar que los dos enfoques suelen ser equivalentes para problemas simples, también es cierto que pueden divergir en gran medida en otras situaciones, esta divergencia suele manifestarse de dos maneras diferentes:\n",
        "\n",
        "1. El manejo de parámetros molestos: es decir, parámetros que afectan el resultado final, pero que no son de interés en ningún otro sentido.\n",
        "\n",
        "Un parámetro molesto es cualquier cantidad cuyo valor no es directamente relevante para el objetivo de un análisis, pero que sin embargo, es necesario para determinar el resultado que interesa.\n",
        "2. El diferente manejo de la incertidumbre: por ejemplo, la diferencia sutil (y a menudo pasada por alto) entre los intervalos de confianza frecuentistas y las regiones creíbles bayesianas.\n",
        "\n",
        "A continuación discutiremos ejemplos de esto."
      ],
      "metadata": {
        "id": "WpFPj3duABKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 2: El juego de billar de Bayes\n",
        "\n",
        "Se trara de un juego de apuestas en el que Alicia y Bob apuestan sobre el resultado de un proceso que no pueden observar directamente.\n",
        "Alice y Bob entran en una habitación, detrás de una cortina hay una mesa de billar, que no pueden ver, su amiga Carol hace rodar una bola por la mesa y marca dónde cae. Una vez que la marca está en su lugar, Carol comienza a hacer rodar nuevas bolas por la mesa. Si la bola cae a la izquierda de la marca, Alice obtiene un punto; si cae a la derecha de la marca, Bob obtiene un punto. Podemos suponer que los lanzamientos de Carol son imparciales: es decir, las bolas tienen la misma probabilidad de terminar en cualquier lugar de la mesa. La primera persona que alcance los seis puntos gana el juego, en este caso, la ubicación de la marca (determinada por el primer lanzamiento) puede considerarse un parámetro molesto: es desconocido y no tiene interés inmediato, pero claramente debe tenerse en cuenta al predecir el resultado de los lanzamientos posteriores. Si el primer lanzamiento se establece muy a la derecha, los lanzamientos posteriores favorecerán a Alice. Si se establece muy a la izquierda, Bob será el favorecido. Con esta configuración, buscamos responder a esta pregunta: en un juego en particular, después de ocho lanzamientos, Alice tiene cinco puntos y Bob tiene tres puntos. ¿Cuál es la probabilidad de que Bob obtenga seis puntos y gane el juego?. Intuitivamente, nos damos cuenta de que, como Alice recibió cinco de los ocho puntos, la ubicación del marcador probablemente la favorezca. Dado que tiene tres oportunidades de obtener un sexto punto antes de que Bob pueda ganar, parece que lo ha conseguido. Pero, cuantitativamente hablando, ¿cuál es la probabilidad de que Bob persista para ganar?"
      ],
      "metadata": {
        "id": "Yjog7T1VDW8F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### -> Un enfoque frecuentista ingenuo\n",
        "\n",
        "Como cinco bolas de ocho caveron en el lado del marcador de Alicia, calculamos la estimación de máxima verosimilitud de p, dada por:\n",
        "\n",
        "$$\\hat{p} = \\frac{5}{8}$$\n",
        "\n",
        "De la probabilidad binomial se sigue un resultado de manera directa. Suponiendo esta probabilidad máxima, podemos calcular la probabilidad de que Bob gane, lo que requiere que obtenga un punto en cada uno de los tres lanzamientos siguientes. Esto viene dado por:\n",
        "\n",
        "$$P(B)=(1-\\hat{p})^3$$\n",
        "\n",
        "lo implementamos de la siguiente manera"
      ],
      "metadata": {
        "id": "4Z-6E2okFuXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p_hat = 5/8\n",
        "P_B = (1-p_hat)**3\n",
        "print(\"La probabilidad de que Bob gane es: \",round(P_B,2))"
      ],
      "metadata": {
        "id": "auiZ5pLXGwF2",
        "outputId": "663d4502-bd5d-40b8-aac2-a1e88c7eb8d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La probabilidad de que Bob gane es:  0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### -> Enfoque bayesiano\n",
        "Un enfoque bayesiano para este problema implica marginalizar (es decir, integrar) la $p$ desconocida de modo que, suponiendo que la anterior sea precisa, nuestro resultado sea independiente de su valor real.\n",
        "En este sentido, consideraremos las siguientes cantidades:\n",
        "1. $B=$ Bob gana.\n",
        "2. $D=$ Datos observados, es decir $D=(5,3)$\n",
        "3. $\\rho =$ probabilidad desconocida de que una pelota caiga en el lado de\n",
        "Alicia durante el juego actual.\n",
        "Comenzamos aplicando la definición de probabilidad condicional para\n",
        "expandir el término $P(B,\\rho|D)$:\n",
        "\n",
        "$$P(B|D)=\\int P(B|\\rho,D)P(\\rho|D)d\\rho$$\n",
        "\n",
        "Finalmente, utilizando la misma identidad de probabilidad con la que comenzamos, podemos expandir $P(D)$ en el denominador para encontrar:\n",
        "\n",
        "$$P(B|D)=\\frac{\\int P(B|\\rho,D)P(D|\\rho)P(\\rho)d\\rho}{\\int P(D|\\rho)P(\\rho)d\\rho}$$\n",
        "\n",
        "donde:\n",
        "\n",
        "* $P(B∣\\rho,D):$ Es la probabilidad de que Bob gane tres veces seguidas dados un valor de $\\rho$ (probabilidad de ganar un juego) y los datos $D$. Se calcula como $(1-\\rho)^3$\n",
        "* $P(D|\\rho):$ Es la probabilidad de obtener exactamente 5 éxitos (victorias de Alice) en 8 intentos, dado el valor $\\rho$. Esto se obtiene usando la distribución binomial:\n",
        "$P(D|\\rho)$ -> $\\rho^5 (1-\\rho)^3$\n",
        "* $P(\\rho):$ Es la probabilidad a priori de $\\rho$. En este caso, se asume que $\\rho$ es uniforme entre 0 y 1.\n",
        "\n",
        "por lo que\n",
        "\n",
        "$$P(B|D)=\\frac{\\int_{0}^{1} (1-\\rho)^6 \\rho^5 d\\rho}{\\int_{0}^{1} (1-\\rho)^3 \\rho^5 d\\rho}$$\n",
        "\n",
        "Estas integrales son instancias de la función beta, por lo que podemos\n",
        "evaluar rápidamente el resultado usando scipy:\n"
      ],
      "metadata": {
        "id": "WtyZbZzLG6Cr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import beta # Se importa la función beta\n",
        "P_B_D = beta(6+1, 5+1) / beta(3+1, 5+1) # los valores pueden representar el número de éxitos y fracasos en un contexto de estimación bayesiana\n",
        "print(\"La probabilidad de que Bob gane es: \",round(P_B_D,2))"
      ],
      "metadata": {
        "id": "bxRhhHFNOcvj",
        "outputId": "40f28627-4d29-4572-cc9d-fb02a7879330",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La probabilidad de que Bob gane es:  0.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El enfoque bayesiano da probabilidades de 10 a 1 en contra de Bob, mientras que el enfoque frecuentista ingenuo da probabilidades de 18 a 1 en contra de Bob. Entonces, ¿cuál es correcto?\n",
        "Para un problema tan simple como este, podemos responder a esta pregunta empíricamente simulando una gran cantidad de juegos y contando la fracción de juegos adecuados que Bob gana. El resultado de dicha simulación confirma el resultado\n",
        "bayesiano: 10 a 1 en contra de la victoria de Bob. ¿El frecuentismo es incorrecto?, no necesariamente: en este caso, el resultado incorrecto es más una cuestión de que el enfoque sea \"ingenuo\" que de que sea\n",
        "\"frecuentista\"."
      ],
      "metadata": {
        "id": "TbqPi5q0PNFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confianza vs. Credibilidad\n",
        "\n",
        "A la hora de construir un límite estándar del 95% sobre un parámetro $\\theta$:\n",
        " * Un bavesiano diría: \"Dados nuestros datos observados, hay un 95% de probabilidad de que el verdadero valor de $\\theta$ se encuentre dentro de la región creíble\".\n",
        " * Un frecuentista diría: \"Si este experimento se repite muchas veces, en el 95% de estos casos el intervalo de confianza calculado contendrá el verdadero 0.25\".\n",
        "\n",
        "Observemos la sutil diferencia: el bayesiano enuncia una probabilidad sobre el valor del parámetro dada una región creíble fija. El frecuentista enuncia una probabilidad sobre el intervalo de confianza en sí dado un valor de parámetro fijo. Esta distinción se desprende directamente de la definición de probabilidad que se ha analizado anteriormente, la probabilidad bayesiana es una afirmación del grado de conocimiento sobre un parámetro, la probabilidad frecuentista es una afirmación de la frecuencia límite a largo plazo de las cantidades (como el intervalo de confianza) derivadas de los datos.\n",
        "\n",
        "El frecuentismo no busca una afirmación probabilística sobre un intervalo fijo, como lo hace el enfoque bayesiano; en cambio, busca afirmaciones probabilísticas sobre un conjunto de intervalos construidos, siendo el intervalo calculado particular sólo una única extracción de entre ellos."
      ],
      "metadata": {
        "id": "ShqSwiNwRR0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 3 (Bayesianismo): El método Monte Carlo con cadenas de Markov\n",
        "\n",
        "Un punto de inflexión en la computación bayesiana práctica fue el desarrollo y la aplicación de métodos de muestreo como Markov Chain Monte Carlo, los cuales son una clase de algoritmos que pueden caracterizar de manera eficiente incluso distribuciones posteriores de alta dimensión mediante la extracción de muestras\n",
        "aleatorias de manera que los puntos se distribuyan de acuerdo hacia la parte posterior.\n",
        "A continuación, propondremos vemos modelo sencillo y compararemos un enfoque frecuentista estándar\n",
        "con tres implementaciones de MCMC disponibles en Python.\n",
        "\n"
      ],
      "metadata": {
        "id": "3hTtL8FWTs5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### -> Un modelo lineal simple\n",
        "Consideremos un modelo lineal simple de tres parámetros que ajusta una línea recta a datos con errores desconocidos. Los parámetros serán la intersección con el eje $\\alpha$, la pendiente $\\beta$ y la dispersión normal (desconocida) o sobre la línea.\n",
        "Para los datos $D = {(xi, yi)}$, el modelo es\n",
        "\n",
        "$$ \\hat{y}(x_i|\\alpha,\\beta)=\\alpha + \\beta x_i$$\n",
        "\n",
        "y la probabilidad es el producto de la distribución gaussiana para cada\n",
        "punto:\n",
        " $$\\mathscr{L}(D|\\alpha,\\beta,\\sigma)=(2\\pi\\sigma^2)^{-\\frac{N}{2}} \\prod_{i=1}^{N} \\text{ exp }[\\frac{-{[y_i-\\hat{y}(x_i|\\alpha,\\beta)]^2}}{2\\sigma^2}] $$\n",
        "\n",
        " Evaluaremos este modelo en el siguiente conjunto de datos:\n"
      ],
      "metadata": {
        "id": "7Fog8YSKUyfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42) # Fija la semilla del generador de números aleatorios para asegurar la reproducibilidad de los resultados\n",
        "theta_true = (25, 0.5) # Define los parámetros del modelo lineal (intersección y pendiente)\n",
        "xdata = 100 * np.random.random(20) # Genera 20 valores aleatorios de x entre 0 y 100\n",
        "ydata = theta_true[0] + theta_true[1] * xdata # Calcula los valores de y correspondientes a la línea recta\n",
        "ydata = np.random.normal(ydata, 10) # # Agrega ruido aleatorio a los valores de y con una desviación estándar de 10\n"
      ],
      "metadata": {
        "id": "CPsQKXJMRSiw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####-> Solución frecuentista\n",
        "\n",
        "Se puede encontrar una solución frecuentista calculando la estimación puntual de máxima verosimilitud.\n",
        "Si definimos el vector $\\theta = [\\alpha \\beta]^T$ el vector de respuesta, $Y=[y_1 , y_2, y_3 , ... , y_N]^T$ y la matriz de diseño:\n",
        "\n",
        "$$\\begin{equation}\n",
        "\\begin{bmatrix}\n",
        " 1 & 1 & 1 & ... & 1\\\\\n",
        "x_1 & x_2 & x_3 & ... & x_N\n",
        "\\end{bmatrix}\n",
        "\\end{equation}$$\n",
        "\n",
        "Se puede demostrar que la solución de máxima verosimilitud\n",
        "\n",
        "$$\\hat{\\theta}=(X^T X )^{-1} (X^T Y) $$"
      ],
      "metadata": {
        "id": "UNdeMb1cS4KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.vstack([np.ones_like(xdata), xdata]).T #Creamos la matriz X de diseño para el modelo de regresión lineal\n",
        "theta_hat = np.linalg.solve(np.dot(X.T, X),np.dot(X.T, ydata)) #np.dont(..) calcula el producto de matrices\n",
        "                                                               # np.linalg.solve(...) resuelve el sistema de ecuaciones para obtener theta\n",
        "y_hat = np.dot(X, theta_hat) # Se predice el valor de y tomando en cuenta los coeficientres obtenidos por theta\n",
        "sigma_hat = np.std(ydata - y_hat) # Se calcula la desviación estándar de los residuos (errores)\n",
        "Sigma = sigma_hat ** 2 *  np.linalg.inv(np.dot(X.T, X)) # Se calcula la matriz de covarianza de los estimadores de los coeficientes theta"
      ],
      "metadata": {
        "id": "6DBIG8D6FgS9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la práctica, el enfoque frecuentista suele depender de muchos más diagnósticos estadísticos que la máxima verosimilitud y el intervalo de confianza. Para este problema, se puede utilizar de la siguiente manera:"
      ],
      "metadata": {
        "id": "A35m9N0f4xWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm # version 0.5\n",
        "X = sm.add_constant(xdata) # sm.add_constant(...) agrega un término constante al conjunto de datos de entrada xdata\n",
        "result = sm.OLS(ydata, X).fit() # sm.OLS(...) crea un modelo de regresión lineal utilizando el metodo de minimos cuadrados\n",
        "                                # .fit(...) ajusta el modelo a los datos, estimando los coeficientes de la regresión\n",
        "sigma_hat = result.params    # Contiene los coeficientes estimados (o parámetros) del modelo\n",
        "Sigma = result.cov_params()   # Contiene la matriz de covarianza de los coeficientes estimados\n",
        "print(result.summary2())  # Imprime un resumen detallado de los resultados del ajuste del modelo de regresión"
      ],
      "metadata": {
        "id": "nPtvbfJ85FRf",
        "outputId": "d08aae7d-0a59-458c-db9e-60abdb18cfed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Results: Ordinary least squares\n",
            "=================================================================\n",
            "Model:              OLS              Adj. R-squared:     0.683   \n",
            "Dependent Variable: y                AIC:                147.7737\n",
            "Date:               2024-10-08 12:08 BIC:                149.7651\n",
            "No. Observations:   20               Log-Likelihood:     -71.887 \n",
            "Df Model:           1                F-statistic:        41.97   \n",
            "Df Residuals:       18               Prob (F-statistic): 4.30e-06\n",
            "R-squared:          0.700            Scale:              86.157  \n",
            "-------------------------------------------------------------------\n",
            "            Coef.    Std.Err.     t      P>|t|     [0.025    0.975]\n",
            "-------------------------------------------------------------------\n",
            "const      24.6361     3.7871   6.5053   0.0000   16.6797   32.5924\n",
            "x1          0.4483     0.0692   6.4782   0.0000    0.3029    0.5937\n",
            "-----------------------------------------------------------------\n",
            "Omnibus:              1.996        Durbin-Watson:           2.758\n",
            "Prob(Omnibus):        0.369        Jarque-Bera (JB):        1.634\n",
            "Skew:                 0.651        Prob(JB):                0.442\n",
            "Kurtosis:             2.486        Condition No.:           100  \n",
            "=================================================================\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the\n",
            "errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podríamos imaginarnos cómo abordar este problema transformando las varables, por ejemplo, haciendo uso del Prior de Jeffreys en el contexto de un modelo de regresión lineal. Se propone transformar variables utilizando un prior plano en el ángulo que la línea forma con el eje $x$, en lugar de usar la pendiente. A través de transformaciones y usando el Jacobiano, se deduce que la probabilidad conjunta de los parámetros $\\alpha$ y $\\beta$ debe ser proporcional a $$(1+\\beta^2)^{\\frac{3}{2}}$$\n",
        "\n",
        "por lo que se argumenta que para el parámetro $\\sigma$ (la desviación estándar), el Prior de Jeffreys es inversamente proporcional a $\\sigma$, es decir, $$P(\\sigma)∝1/\\sigma$$, lo que equivale a un prior plano en el logaritmo de $\\sigma$,por lo que el prior no informativo para el problema de regresión lineal es proporcional a $$\\frac{1}{\\sigma}(1+\\beta^2)^{-\\frac{3}{2}}$$ y se puede usar este prior junto con la verosimilitud para evaluar el posterior usando métodos como MCMC.\n",
        "\n"
      ],
      "metadata": {
        "id": "CB31fFJD6XlM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solición con presentador\n",
        "\n",
        "El paquete emcee en Python, implementa un método de muestreo MCMC llamado Affine Invariant Ensemble MCMC. Este método es una versión avanzada de MCMC, propuesto por Goodman y Weare en 2010. El paquete emcee es ligero y fácil de usar, ya que solo requiere definir una función en Python que represente el logaritmo del posterior.\n",
        "\n",
        "Para mayor claridad, la definición del posterior se descompone en dos partes: el log-prior (logaritmo del prior) y el log-likelihood (logaritmo de la verosimilitud), que se utilizan para el muestreo."
      ],
      "metadata": {
        "id": "RqQSiLxR9dlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emcee # Installs the emcee package if it's not already installed\n",
        "\n",
        "import emcee # librería para realizar muestreo de cadenas de Markov\n",
        "import numpy as np # Make sure to import numpy\n",
        "\n",
        "\n",
        "def log_prior(theta):\n",
        "    alpha, beta, sigma = theta\n",
        "    if sigma < 0:\n",
        "        return -np.inf\n",
        "    else:\n",
        "        return (-1.5 * np.log(1 + beta ** 2) - np.log(sigma))\n",
        "\n",
        "def log_like(theta, x, y):  # Funcion de verosimilitud\n",
        "    alpha, beta, sigma = theta\n",
        "    y_model = alpha + beta * x\n",
        "    # Fix: Use np.pi * sigma instead of np.pisigma\n",
        "    return -0.5 * np.sum(np.log(2 * np.pi * sigma ** 2) + (y - y_model) ** 2 / sigma ** 2)\n",
        "\n",
        "def log_posterior(theta, x, y):\n",
        "    return log_prior(theta) + log_like(theta, x, y)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "9eZWZg359w98",
        "outputId": "2c1522a0-54a1-4dae-d075-b93ccc19d10f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emcee in /usr/local/lib/python3.10/dist-packages (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from emcee) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, configuramos el cálculo. emcee combina varios \"caminantes\" que interactúan, cada uno de los cuales genera su propia cadena de Markov. También especificaremos un período de rodaje para permitir\n",
        "que las cadenas se estabilicen antes de dibujar los trazos finales:"
      ],
      "metadata": {
        "id": "g7RdknphActv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ndim=3 # Indica que se muestrearán tres parámetros del modelo\n",
        "nwalkers=50 # Utiliza 50 caminantes para explorar el espacio de parámetros.\n",
        "nburn=100 # Descartará los primeros 100 pasos de cada caminante\n",
        "nsteps=20 # Indica que los caminantes realizarán 20 pasos después del \"burn-in\"\n",
        "starting_guesses=np.random.rand(nwalkers,ndim) #Los caminantes comienzan en posiciones aleatorias en un cubo tridimensional de valores entre 0 y 1."
      ],
      "metadata": {
        "id": "s_iaRzXf-Z8z"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler=emcee.EnsembleSampler(nwalkers,ndim,log_posterior,args=[xdata,ydata])\n",
        "sampler.run_mcmc(starting_guesses,nsteps) # se ejecuta el muestreo"
      ],
      "metadata": {
        "id": "baF_VmTRBVPe",
        "outputId": "d44cbaf8-6712-4367-eb83-584b1a834bb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State([[ 0.65738225  0.17896382  0.48526873]\n",
              " [ 4.77439609  0.80864009  3.65440273]\n",
              " [ 0.37681184  0.64035215  1.67296433]\n",
              " [ 0.70632561  0.5727329   1.52705153]\n",
              " [ 0.52971352  0.65932898  1.20480199]\n",
              " [ 0.80887907  0.63203405  1.57516723]\n",
              " [ 3.59929227  0.52026662 10.18797767]\n",
              " [ 1.12539942  0.42347828  0.99078842]\n",
              " [ 0.6204726   0.59799504  1.07037243]\n",
              " [-0.77453494  0.84995627  1.69650513]\n",
              " [ 0.62296561  0.61567063  1.97449423]\n",
              " [ 0.47445131  1.07312812  3.20578462]\n",
              " [ 1.39005347  0.80222785  1.7396511 ]\n",
              " [ 2.01404288  0.99683924  3.44596466]\n",
              " [ 1.41855147  0.90647666  2.56852288]\n",
              " [ 7.4754023   0.92598969  7.01002422]\n",
              " [ 0.61471288  0.6337686   1.07708505]\n",
              " [-0.28300376  0.88277113  2.08917015]\n",
              " [ 0.19210965  0.92450802  1.44293917]\n",
              " [ 0.90424868  0.69842503  2.94894337]\n",
              " [ 0.58960603  0.41022032  3.42573721]\n",
              " [ 1.63164901  0.51031431  3.34556919]\n",
              " [ 0.74598567  0.72057899  1.23860345]\n",
              " [ 1.43833881  0.87390015  1.74328815]\n",
              " [ 0.36034427  0.68911741  1.68503082]\n",
              " [ 0.86748526  0.51068059  1.23298743]\n",
              " [-0.164497    0.93307651  1.1374766 ]\n",
              " [-0.11140801  0.29036888  3.12061541]\n",
              " [-0.29138385  0.75216625  2.10364695]\n",
              " [ 1.07391062  0.66339124  3.00311113]\n",
              " [ 0.16760034  0.59308012  2.25473121]\n",
              " [-0.9716838   0.57647085  3.61736296]\n",
              " [ 0.3947431   0.807693    1.63667226]\n",
              " [ 0.53151163  0.7831047   1.18890784]\n",
              " [ 0.54035391  0.37413095  1.16719546]\n",
              " [ 1.22398355  1.06888482  3.91006391]\n",
              " [ 0.31581311  0.67175648  1.10664361]\n",
              " [ 1.31635454  0.20752964  7.85812606]\n",
              " [-0.2680314   0.80952244  1.55320281]\n",
              " [ 0.51367087  0.7794367   0.8288106 ]\n",
              " [ 0.53070555  0.77638272  0.65039353]\n",
              " [ 1.23425015  0.28588659  2.60869275]\n",
              " [ 0.01817515  0.78870222  0.75904823]\n",
              " [ 0.22304165  0.86699942  0.81694096]\n",
              " [ 0.48065879  0.65008003  2.33093256]\n",
              " [ 1.58828986  0.88810722  2.14886381]\n",
              " [ 1.1895024   0.80198412  4.78177369]\n",
              " [ 0.87587793  0.68070769  1.35324816]\n",
              " [ 0.61606059  0.62801288  1.49443794]\n",
              " [ 0.77452665  0.82862692  2.44316542]], log_prob=[-62049.64026549   -200.34188134  -1280.41936233  -1846.08126119\n",
              "  -2271.23939597  -1421.55008902   -105.73935483  -7003.16223916\n",
              "  -3444.88983643   -975.37321901   -982.69891181   -480.18894045\n",
              "   -823.30324422   -343.7414753    -450.41052554   -122.23386603\n",
              "  -3035.53420995   -659.35016178  -1412.5400264    -369.09511281\n",
              "   -678.47599207   -479.85414862  -1814.97627849   -867.51978905\n",
              "  -1105.48457287  -3433.69369538  -2307.41473436  -1195.16093645\n",
              "   -671.98447239   -382.81835909   -851.80357349   -414.2449097\n",
              "   -979.27883006  -1830.02504254  -6175.44203896   -341.68427322\n",
              "  -2642.94823253   -273.72870356  -1126.72875905  -3750.06756507\n",
              "  -6084.7788245   -1584.8407273   -4585.75356436  -3951.93189691\n",
              "   -656.5819495    -598.36763564   -158.14142641  -1654.56722976\n",
              "  -1621.81049608   -455.54677967], blobs=None, random_state=('MT19937', array([4117920049, 3603157967, 3447132721, 1607314950, 1737520717,\n",
              "        504493538, 1791851239,  641308920, 3817890668, 4220927451,\n",
              "       3330580951, 1440059349, 3044363306, 3518703381,  913397075,\n",
              "       2895121632, 4016548021,  862559804, 3080294846, 2176727794,\n",
              "        692889719, 3101353344, 3237988755,  528607439,  650823188,\n",
              "       1098648111, 2061063606, 2829538010,  588762277, 4073065135,\n",
              "       3653525013, 1223584541, 2517351566,  638499099, 3058740897,\n",
              "       3171495246, 3220611511, 1189768517, 2836135479, 4113635703,\n",
              "       3600392752, 2729501998, 1158526717,  452397514, 1803524326,\n",
              "       1415393823, 1484481797,  402562493, 2683145376,  369328382,\n",
              "        586825033,   34666384,  223732549, 2963143616, 2932963614,\n",
              "       3194796696, 2618564335, 3485279165, 3747095107, 3614857701,\n",
              "       3060183858, 2052520240, 3397979694,  420615696,  782397340,\n",
              "       1440409824, 2205877238, 1575561529, 2806489198, 3425656211,\n",
              "        934838066, 2249924872, 2449271549,  522828510, 2708781861,\n",
              "       2098696341, 3548294164,  349099094,  691653161, 1349273859,\n",
              "       1554572003, 1644372784, 1174218127, 1626265843, 3803634780,\n",
              "       3413098260, 3164474822, 1057771022, 1101634588,  615695364,\n",
              "       2788174504, 1522977997,  446497217,  698745087,  707871405,\n",
              "       3269214305, 2047007397, 1721091101,  289955586, 1557661344,\n",
              "       2537064376, 2195879424, 1620037967, 1226916065, 2861921124,\n",
              "       1848706701, 1368253548, 3333598354, 4019404724, 3727661368,\n",
              "       1742883818, 2209430529, 1416679376,  662741568, 1490174841,\n",
              "       3495266319,  763195134, 2694179709, 1913222181, 4219104729,\n",
              "        668148018, 1546072712, 2571425994, 1903440946, 1500260169,\n",
              "         96315999,  873753054, 2215378018, 1124438396, 1312231192,\n",
              "        505512419, 4137770189, 3846122983, 4080502002,  141791882,\n",
              "       3632836087,  534160012, 3321230728, 2609917856, 2963029572,\n",
              "       1662331851,  172844807, 1257673243, 4035614255, 1174255614,\n",
              "        664553940, 4232297942, 2995814000, 3540611960, 1373355782,\n",
              "       1024739872,  568244963, 1630368433,  622486860, 2272006705,\n",
              "       1961249365, 1894741712, 1936177335, 2526106938, 2023921293,\n",
              "       1109440302, 3226330828, 2272451872, 2877086807, 2098514455,\n",
              "        624894053, 4095597869, 3580724848, 3172736855, 2006213658,\n",
              "        923776051, 3826843677, 1055204904, 3757007172,  486277504,\n",
              "       3515724764,  725199926,  967827141, 2290537949, 1035681888,\n",
              "       3900208284, 1183899171, 3547356950, 4061781854,  236197262,\n",
              "       2549387064, 3162548102, 1513391011, 2133044962, 1711228855,\n",
              "       1280978353, 1864019118,  173962131, 3820721746, 1014092340,\n",
              "       1301141485, 2983500519, 4022992786, 3880950488, 3100004915,\n",
              "       4231818521,  985294379,  334115963,  556429342, 1390243611,\n",
              "       1231313993, 1183005837, 2004125454, 2754259558, 2696069895,\n",
              "       4271405538, 1119793797, 1845731760,  247461914, 3738465418,\n",
              "        159993582,  124055479, 2798809073, 3566642990, 2541125743,\n",
              "       2358766540,  462627097,  728522806, 1572802876, 1734839761,\n",
              "        516280697,  863522004,  683688369,  673039721, 2543654896,\n",
              "        102978079,  314474394, 1764316270,  205354060, 4036280972,\n",
              "       3284033595,  607417336,    5888880, 2632213297, 2458057723,\n",
              "       1249484725, 2787858020, 2433003967,  845918549,  596103303,\n",
              "       1945154389, 4097328113,  531493290, 2777281196, 2485585544,\n",
              "       3544495877, 2377768215, 3002590169,  376990238, 2899611376,\n",
              "       1580102643, 3377582089, 3521416067, 1106136928, 3753425928,\n",
              "       2025693479,  583689807, 3203531711, 4274416513,  164499994,\n",
              "       1587566719,   73346895, 3155798534, 2565693203, 3525043806,\n",
              "       3291160024, 4211819962,   69181636, 4085584466, 1967924222,\n",
              "        771963443, 1989005475, 3456086169, 3159814249,  957338546,\n",
              "         85722160, 4251018588, 2956896232,  345796570,  997695271,\n",
              "       2769321122, 3792873878,  555872768, 3414730338,  501626817,\n",
              "       2165236208, 2704681473, 3613503451, 1694033759, 2037247404,\n",
              "        667275530, 1940442118, 3585457848, 1095060382, 1420856011,\n",
              "          2581639, 1032341377, 2618110920, 3069328522, 3246715373,\n",
              "         17974851, 2791464129,  248641383, 3905004965, 2508291908,\n",
              "       1295484038, 2563664284, 2457456590, 3321652996, 2333210367,\n",
              "       1259015828, 3622939955, 3106688395, 2312342909, 2832630779,\n",
              "       2103415652, 2258870285, 2272424851, 2536882888, 4226321192,\n",
              "       1242890343,  964476494, 1833148686, 4003545815, 3941512214,\n",
              "       1560848682, 3885466910, 3436970745,  236224611, 2428477918,\n",
              "        548534611, 2212373798,  608152512, 1191170679, 1931007827,\n",
              "       4278627864, 3787089456, 2337378875, 4245902274, 3768888224,\n",
              "       3953904980,  407614035, 2833875699, 3740869890, 1654984663,\n",
              "        253312494, 3363339807, 2922063846,   59582876, 1079138821,\n",
              "       3567375449, 3390652518, 3172764740,  826004340, 2517195763,\n",
              "       3262259032, 4272151804, 1616285557, 4200530225, 1667535753,\n",
              "       2750573117,   14222275,  965661501, 3279148690, 2172821463,\n",
              "       3425073419, 3222104107, 3574969934, 2571850767,  671435303,\n",
              "       2458218707, 4204246527, 3259131126,  491568505, 1628915827,\n",
              "       2557518611, 1012221975, 1441015939, 2759870704, 4273515451,\n",
              "       3135489742, 4194302501, 1991134962,  351202753, 2783150248,\n",
              "       2799263238, 3670025511, 1658024065, 3397477216, 4181200436,\n",
              "       2378073184, 3000728053,  226471479, 3552336666,  569088229,\n",
              "       1127208166, 1475380202,  793812532, 3673348377, 2396100390,\n",
              "       3060377824,   24395514, 1801999071, 2080042322, 3262774364,\n",
              "       2762862890, 4049269150, 3504729395, 3155239889, 1258186679,\n",
              "        669912868, 1324267419, 2092284495,  455103447, 4104887758,\n",
              "       1472812229, 3469771396, 3532023271,  241123759,  959161716,\n",
              "       1547644881, 2945780563, 3493617544, 1568027086, 1287598897,\n",
              "       3435268366, 3328173074,  636402972, 3846203489,  305171237,\n",
              "        956425014, 3930118842, 1007083050,  225954420, 3159174077,\n",
              "       3474918493,  889145556, 3542950955, 1401512021, 1851763143,\n",
              "       1960207743, 2744680115, 3982905159, 3158817563, 3856959334,\n",
              "       3220903389, 2969789779,  461629384, 2210557534, 3664098915,\n",
              "       3368858042, 3676796105, 4160423481, 1587044849,  266983759,\n",
              "       3822998356, 3376554004, 1225876085, 2308376108, 3062956085,\n",
              "       4120998671,  463814203, 2598257415, 2911890854, 3566150121,\n",
              "       1488143142, 3647304423,  886521183,  317996249, 3756705862,\n",
              "       3790652055, 3541077558, 4204545546, 2205841089, 4173075512,\n",
              "        670459222,  548287578, 3162187051, 4124981855, 1126953771,\n",
              "       3421498368, 4106472879, 3093969038, 1797542990, 2536088845,\n",
              "       3912249844, 3685947620, 1997342181, 3825577796, 2368992370,\n",
              "       1037199487, 2840906232, 2945616636, 3327856069, 2876555539,\n",
              "       2680389009, 2443564370, 2361012393, 2579778970, 2136931451,\n",
              "       1633909473,  617226343, 2974236078, 2224873308, 1927785126,\n",
              "       2195148584, 2707444881, 2889589126, 3050765586,  601655458,\n",
              "       4024416170, 2748315458, 3399295704, 3461885231, 2903827080,\n",
              "       3031018539,  805783304, 1369645064, 1177600776, 3770102110,\n",
              "       1990378817,  676694912,  693007128, 1800398835, 1305616036,\n",
              "       1116527615, 2572468177, 1046988067, 1881000649, 1088165435,\n",
              "       2669098094,  349430580, 2233153575, 3422265118, 3324850634,\n",
              "       3909680044, 3446199320, 3551799416, 2901962367, 2996876982,\n",
              "       3252713898, 2604179829, 3766563518, 3359640100, 1076294726,\n",
              "       3621006555, 2854514275, 4205853639, 2857702269, 2650858941,\n",
              "       2803595036,  350338513,  211167644, 3166783310, 4242962266,\n",
              "       1321628501,  675577338,  161604093,  508023433, 3669646834,\n",
              "       2780857586,  214020516, 1537588195, 2255550936, 1255183591,\n",
              "       3317103977, 1341812583, 2152333967, 2003926480, 2836897405,\n",
              "       3025553466, 3168053254, 2925306547, 2204340829,  847692451,\n",
              "       3542678665, 3390936871, 3892292145, 2180934159, 1980350382,\n",
              "       1807927136, 2611539469,  856151143, 3581899426, 3485646538,\n",
              "          7274658, 2387205659, 2691477063, 1994734442,  351828699,\n",
              "       3433139682,  521801243, 3229627454,  804756630, 1184140263,\n",
              "       2262259529, 4018123629,  296069999, 1958830964, 2593573569,\n",
              "        486468255,  819807908, 1538244780, 4024621755, 3918052445,\n",
              "       2521423091,  438513346, 3951697658, 2628525411, 2691972855,\n",
              "       1686567890, 1573754242, 1911939954, 3390420056, 2010192169,\n",
              "       3998728984, 1806031207, 3394551303, 1365964210], dtype=uint32), 242, 0, 0.0))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuacio se muestra un paquete que utiliza el clásico muestreador Metropolis-Hastings y ofrece muchas características integradas, como soporte para el muestreo eficiente de distribuciones previas comunes. Debido a estas capacidades, PyMC requiere un poco más de configuración inicial en comparación con emcee, pero resulta ser una herramienta muy poderosa para realizar inferencias bayesianas flexibles."
      ],
      "metadata": {
        "id": "Q0Z5PoyuC9Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymc3 #Install PyMC3\n",
        "import pymc3 as pm #Import PyMC3 as pm"
      ],
      "metadata": {
        "id": "ztxUyzfwFHMD",
        "outputId": "c1940d5b-c071-48dc-9ccc-7187e6754c67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymc3 in /usr/local/lib/python3.10/dist-packages (3.11.6)\n",
            "Requirement already satisfied: arviz>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from pymc3) (0.20.0)\n",
            "Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.10/dist-packages (from pymc3) (5.5.0)\n",
            "Requirement already satisfied: deprecat in /usr/local/lib/python3.10/dist-packages (from pymc3) (2.1.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from pymc3) (0.3.9)\n",
            "Requirement already satisfied: fastprogress>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from pymc3) (1.0.3)\n",
            "Collecting numpy<1.22.2,>=1.15.0 (from pymc3)\n",
            "  Using cached numpy-1.22.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from pymc3) (2.0.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from pymc3) (0.5.6)\n",
            "Collecting scipy<1.8.0,>=1.7.3 (from pymc3)\n",
            "  Using cached scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: semver>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from pymc3) (3.0.2)\n",
            "Requirement already satisfied: theano-pymc==1.1.2 in /usr/local/lib/python3.10/dist-packages (from pymc3) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pymc3) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from theano-pymc==1.1.2->pymc3) (3.16.1)\n",
            "Requirement already satisfied: setuptools>=60.0.0 in /usr/local/lib/python3.10/dist-packages (from arviz>=0.11.0->pymc3) (71.0.4)\n",
            "Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.10/dist-packages (from arviz>=0.11.0->pymc3) (3.7.1)\n",
            "INFO: pip is looking at multiple versions of arviz to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting arviz>=0.11.0 (from pymc3)\n",
            "  Using cached arviz-0.19.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "  Using cached arviz-0.18.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Using cached arviz-0.17.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Using cached arviz-0.17.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "  Using cached arviz-0.16.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Using cached arviz-0.16.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Using cached arviz-0.15.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "INFO: pip is still looking at multiple versions of arviz to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached arviz-0.15.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Using cached arviz-0.14.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Using cached arviz-0.13.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Using cached arviz-0.12.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from arviz>=0.11.0->pymc3) (24.1)\n",
            "Requirement already satisfied: xarray>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from arviz>=0.11.0->pymc3) (2023.12.0)\n",
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.10/dist-packages (from arviz>=0.11.0->pymc3) (1.7.1.post2)\n",
            "Requirement already satisfied: xarray-einstats>=0.2 in /usr/local/lib/python3.10/dist-packages (from arviz>=0.11.0->pymc3) (0.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->pymc3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->pymc3) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->pymc3) (2024.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->pymc3) (1.16.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecat->pymc3) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->arviz>=0.11.0->pymc3) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->arviz>=0.11.0->pymc3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->arviz>=0.11.0->pymc3) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->arviz>=0.11.0->pymc3) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->arviz>=0.11.0->pymc3) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->arviz>=0.11.0->pymc3) (3.1.4)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.10/dist-packages (from netcdf4->arviz>=0.11.0->pymc3) (1.6.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from netcdf4->arviz>=0.11.0->pymc3) (2024.8.30)\n",
            "Using cached arviz-0.12.1-py3-none-any.whl (1.6 MB)\n",
            "Using cached numpy-1.22.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "Using cached scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.9 MB)\n",
            "Installing collected packages: numpy, scipy, arviz\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "  Attempting uninstall: arviz\n",
            "    Found existing installation: arviz 0.20.0\n",
            "    Uninstalling arviz-0.20.0:\n",
            "      Successfully uninstalled arviz-0.20.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.16 requires numpy>=1.24, but you have numpy 1.22.1 which is incompatible.\n",
            "albumentations 1.4.15 requires numpy>=1.24.4, but you have numpy 1.22.1 which is incompatible.\n",
            "albumentations 1.4.15 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
            "astropy 6.1.4 requires numpy>=1.23, but you have numpy 1.22.1 which is incompatible.\n",
            "bigframes 1.21.0 requires numpy>=1.24.0, but you have numpy 1.22.1 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.22.1 which is incompatible.\n",
            "cudf-cu12 24.6.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.1 which is incompatible.\n",
            "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.22.1 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.22.1 which is incompatible.\n",
            "jax 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.22.1 which is incompatible.\n",
            "jaxlib 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
            "librosa 0.10.2.post1 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you have numpy 1.22.1 which is incompatible.\n",
            "mizani 0.11.4 requires numpy>=1.23.0, but you have numpy 1.22.1 which is incompatible.\n",
            "mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 2.0.3 which is incompatible.\n",
            "numexpr 2.10.1 requires numpy>=1.23.0, but you have numpy 1.22.1 which is incompatible.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.22.1 which is incompatible.\n",
            "plotnine 0.13.6 requires numpy>=1.23.0, but you have numpy 1.22.1 which is incompatible.\n",
            "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 2.0.3 which is incompatible.\n",
            "pymc 5.16.2 requires arviz>=0.13.0, but you have arviz 0.12.1 which is incompatible.\n",
            "rmm-cu12 24.6.0 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.1 which is incompatible.\n",
            "scikit-image 0.24.0 requires numpy>=1.23, but you have numpy 1.22.1 which is incompatible.\n",
            "scikit-image 0.24.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\n",
            "statsmodels 0.14.4 requires numpy<3,>=1.22.3, but you have numpy 1.22.1 which is incompatible.\n",
            "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arviz-0.12.1 numpy-1.22.1 scipy-1.7.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "arviz",
                  "numpy",
                  "scipy"
                ]
              },
              "id": "895dc53506ba47518530ce500ae84ad3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'theano' has no attribute 'compile' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-4bd588fca2fe>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install pymc3 #Install PyMC3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpymc3\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpm\u001b[0m \u001b[0;31m#Import PyMC3 as pm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymc3/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__config__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblas_opt_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblas_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0m_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pymc3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/theano/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0m__api_version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscalar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m from theano.compile import (\n\u001b[1;32m     85\u001b[0m     \u001b[0mIn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/theano/scalar/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic_scipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/theano/scalar/basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;31m# Register C code for ViewOp on Scalars.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m theano.compile.register_view_op_c_code(\n\u001b[0m\u001b[1;32m    711\u001b[0m     \u001b[0mScalar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \"\"\"\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'theano' has no attribute 'compile' (most likely due to a circular import)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = pymc.Uniform('alpha',-100,100)\n",
        "\n",
        "@pymc.stochastic(observed=False)\n",
        "\n",
        "def beta(value=0):\n",
        "  return -1.5 * np.log(1 + value**2)\n",
        "\n",
        "@pymc.stochastic(observed=False)\n",
        "\n",
        "def sigma(value=1):\n",
        "  return -np.log(abs(value))\n",
        "\n",
        "@pymc.deterministic\n",
        "\n",
        "def y_model(x=xdata, alpha=alpha, beta=beta):\n",
        "  return alpha + beta * x\n",
        "\n",
        "y = pymc.Normal('y',mu=y_model,tau=1./sigma**2,observed=True,value=ydata)\n",
        "\n",
        "model=dict(alpha=alpha,beta=beta,sigma=sigma,y_model=y_model,y=y)"
      ],
      "metadata": {
        "id": "gdjAqxcnDJH8",
        "outputId": "c9b5d217-d855-47da-9c2c-7dfb1d52cf81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "No model on context stack, which is needed to instantiate distributions. Add variable inside a 'with model:' block, or use the '.dist' syntax for a standalone distribution.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymc/model/core.py\u001b[0m in \u001b[0;36mget_context\u001b[0;34m(cls, error_if_none, allow_block_model_access)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mcandidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_contexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymc/distributions/distribution.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, rng, dims, initval, observed, total_size, transform, default_transform, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymc/model/core.py\u001b[0m in \u001b[0;36mget_context\u001b[0;34m(cls, error_if_none, allow_block_model_access)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merror_if_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No {cls} on context stack\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: No <class 'pymc.model.core.Model'> on context stack",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-e512f9b97aab>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpymc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mpymc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymc/distributions/distribution.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, rng, dims, initval, observed, total_size, transform, default_transform, *args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    507\u001b[0m                 \u001b[0;34m\"No model on context stack, which is needed to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m                 \u001b[0;34m\"instantiate distributions. Add variable inside \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: No model on context stack, which is needed to instantiate distributions. Add variable inside a 'with model:' block, or use the '.dist' syntax for a standalone distribution."
          ]
        }
      ]
    }
  ]
}